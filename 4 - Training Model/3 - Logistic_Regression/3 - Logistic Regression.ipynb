{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "Some regression algorithms can be used for classification as well (and vice versa). Logistic Regression (also called Logit Regression) is commonly used to estimate the probability that an instance belongs to a particular class (e.g., what is the probability that this email is spam?). If the estimated probability is greater than 50%, then the model predicts that the instance belongs to that class (called the positive class, labeled “1”), or else it predicts that it does not (i.e., it belongs to the negative class, labeled “0”). This makes it a binary classifier.\n",
    "\n",
    "## Estimating Probabilities\n",
    "\n",
    "So how does it work? Just like a Linear Regression model, a Logistic Regression model computes a weighted sum of the input features (plus a bias term), but instead of outputting the result directly like the Linear Regression model does, it outputs the logistic of this result.\n",
    "\n",
    "<img src='images/img1.PNG'>\n",
    "\n",
    "So how does it work? Just like a Linear Regression model, a Logistic Regression model computes a weighted sum of the input features (plus a bias term), but instead of outputting the result directly like the Linear Regression model does, it outputs the logistic of this result following equation.\n",
    "\n",
    "<img src='images/logistic_reg.PNG'>\n",
    "<img src='images/img2.PNG'>\n",
    "\n",
    "\n",
    "Once the Logistic Regression model has estimated the probability  p= hθ(x) that an instance x belongs to the positive class, it can make its prediction ŷ easily:\n",
    "\n",
    "<img src='images/img3.PNG'>\n",
    "\n",
    "Notice that σ(t) < 0.5 when t < 0, and σ(t) ≥ 0.5 when t ≥ 0, so a Logistic Regression model predicts 1 if θT · x is positive, and 0 if it is negative.\n",
    "\n",
    "## Training and Cost Function\n",
    "Good, now you know how a Logistic Regression model estimates probabilities and makes predictions. But how is it trained? The objective of training is to set the parameter vector θ so that the model estimates high probabilities for positive instances (y = 1) and low probabilities for negative instances (y = 0). This idea is captured by the cost function shown in Equation below for a single training instance x.\n",
    "\n",
    "\n",
    "<img src='images/img4.PNG'>\n",
    "\n",
    "This cost function makes sense because – log(t) grows very large when t approaches 0, so the cost will be large if the model estimates a probability close to 0 for a positive instance, and it will also be very large if the model estimates a probability close to 1 for a negative instance. On the other hand, – log(t) is close to 0 when t is close to 1, so the cost will be close to 0 if the estimated probability is close to 0 for a negative instance or close to 1 for a positive instance, which is precisely what we want. \n",
    "\n",
    "The cost function over the whole training set is simply the average cost over all training instances. It can be written in a single expression (as you can verify easily), called the log loss.\n",
    "\n",
    "<img src='images/img5.PNG'>\n",
    "\n",
    "The bad news is that there is no known closed-form equation to compute the value of θ that minimizes this cost function (there is no equivalent of the Normal Equation). But the good news is that this cost function is convex, so Gradient Descent (or any other optimization algorithm) is guaranteed to find the global minimum (if the learning rate is not too large and you wait long enough). The partial derivatives of the cost function with regards to the jth model parameter θj is given by \n",
    "\n",
    "<img src='images/img6.PNG'>\n",
    "\n",
    "For each instance it computes the prediction error and multiplies it by the jth feature value, and then it computes the average over all training instances. Once you have the gradient vector containing all the partial derivatives you can use it in the Batch Gradient Descent algorithm. That’s it: you now know how to train a Logistic Regression model. For Stochastic GD you would of course just take one instance at a time, and for Mini-batch GD you would use a mini-batch at a time.\n",
    "\n",
    "## Decision Boundaries\n",
    "\n",
    "Let’s use the iris dataset to illustrate Logistic Regression. This is a famous dataset that contains the sepal and petal length and width of 150 iris flowers of three different species: Iris-Setosa, Iris-Versicolor, and Iris-Virginica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data', 'target', 'target_names', 'DESCR', 'feature_names']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "iris=datasets.load_iris()\n",
    "list(iris.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X=iris.data[:,3:] # petal width\n",
    "y=(iris.target == 2).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train a logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg=LogisticRegression()\n",
    "log_reg.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c9eabd6c88>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let’s look at the model’s estimated probabilities for flowers with petal widths varying from 0 to 3 cm \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "X_new=np.linspace(0,3,1000).reshape(-1,1)\n",
    "y_proba=log_reg.predict_proba(X_new)\n",
    "plt.plot(X_new,y_proba[:,1],'g-',label='Iris-Virginica')\n",
    "plt.plot(X_new,y_proba[:,0],'b--',label='Not Iris-Virginica')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The petal width of Iris-Virginica flowers ranges from 1.4 cm to 2.5 cm, while the other iris flowers generally have a smaller petal width, ranging from 0.1 cm to 1.8 cm. Notice that there is a bit of overlap. Above about 2 cm the classifier is highly confident that the flower is an Iris-Virginica (it outputs a high probability to that class), while below 1 cm it is highly confident that it is not an Iris-Virginica (high probability for the “Not Iris-Virginica” class). In between these extremes, the classifier is unsure. However, if you ask it to predict the class (using the predict() method rather than the predict_proba() method), it will return whichever class is the most likely. Therefore, there is a decision boundary at around 1.6 cm where both probabilities are equal to 50%: if the petal width is higher than 1.6 cm, the classifier will predict that the flower is an Iris-Virginica, or else it will predict that it is not (even if it is not very confident):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.predict([[1.7],[1.5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below figure shows the same dataset but this time displaying two features: petal width and length. Once trained, the Logistic Regression classifier can estimate the probability that a new flower is an Iris-Virginica based on these two features. The dashed line represents the points where the model estimates a 50% probability: this is the model’s decision boundary. Note that it is a linear boundary.17 Each parallel line represents the points where the model outputs a specific probability, from 15% (bottom left) to 90% (top right). All the flowers beyond the top-right line have an over 90% chance of being Iris-Virginica according to the model.\n",
    "\n",
    "<img src='images/img7.PNG'>\n",
    "\n",
    "Just like the other linear models, Logistic Regression models can be regularized using ℓ1 or ℓ2 penalties. Scitkit-Learn actually adds an ℓ2 penalty by default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax Regression\n",
    "\n",
    "The Logistic Regression model can be generalized to support multiple classes directly, without having to train and combine multiple binary classifiers. This is called Softmax Regression, or Multinomial Logistic Regression.\n",
    "\n",
    "The idea is quite simple: when given an instance x, the Softmax Regression model first computes a score sk(x) for each class k, then estimates the probability of each class by applying the softmax function (also called the normalized exponential) to the scores. The equation to compute sk(x) should look familiar, as it is just like the equation for Linear Regression prediction:\n",
    "\n",
    "<img src='images/img8.PNG'>\n",
    "\n",
    "Note that each class has its own dedicated parameter vector θk. All these vectors are typically stored as rows in a parameter matrix Θ. \n",
    "\n",
    "Once you have computed the score of every class for the instance x, you can estimate the probability k that the instance belongs to class k by running the scores through the softmax function: it computes the exponential of every score, then normalizes them (dividing by the sum of all the exponentials).\n",
    "\n",
    "\n",
    "<img src='images/img9.PNG'>\n",
    "\n",
    "Just like the Logistic Regression classifier, the Softmax Regression classifier predicts the class with the highest estimated probability (which is simply the class with the highest score).\n",
    "\n",
    "<img src='images/img10.PNG'>\n",
    "\n",
    "##### Tip: The Softmax Regression classifier predicts only one class at a time (i.e., it is multiclass, not multioutput) so it should be used only with mutually exclusive classes such as different types of plants. You cannot use it to recognize multiple people in one picture.\n",
    "\n",
    "Now that you know how the model estimates probabilities and makes predictions, let’s take a look at training. The objective is to have a model that estimates a high probability for the target class (and consequently a low probability for the other classes). Minimizing the cost function shown in equation below, called the cross entropy, should lead to this objective because it penalizes the model when it estimates a low probability for a target class. Cross entropy is frequently used to measure how well a set of estimated class probabilities match the target classes.\n",
    "\n",
    "<img src='images/img11.PNG'>\n",
    "Notice that when there are just two classes (K = 2), this cost function is equivalent to the Logistic Regression’s cost function.\n",
    "\n",
    "Now you can compute the gradient vector for every class, then use Gradient Descent (or any other optimization algorithm) to find the parameter matrix Θ that minimizes the cost function. \n",
    "\n",
    "Let’s use Softmax Regression to classify the iris flowers into all three classes. Scikit-Learn’s LogisticRegression uses oneversus-all by default when you train it on more than two classes, but you can set the multi_class hyperparameter to \"multinomial\" to switch it to Softmax Regression instead. You must also specify a solver that supports Softmax Regression, such as the \"lbfgs\" solver (see Scikit-Learn’s documentation for more details). It also applies ℓ2 regularization by default, which you can control using the hyperparameter C.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=iris.data[:,(2,3)]\n",
    "y=iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
       "          n_jobs=1, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax_regression=LogisticRegression(multi_class='multinomial',solver='lbfgs',C=10)\n",
    "softmax_regression.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the next time you find an iris with 5 cm long and 2 cm wide petals, you can ask your model to tell you what type of iris it is, and it will answer Iris-Virginica (class 2) with 94.2% probability (or Iris-Versicolor with 5.8% probability):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax_regression.predict([[5,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.33134078e-07, 5.75276066e-02, 9.42471760e-01]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax_regression.predict_proba([[5,2]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
